{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GM0D-N6CdZ_i"
   },
   "source": [
    "**Author:** Manish KC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCkA86FMztFs"
   },
   "source": [
    "# Introduction to Data Pre-processing\n",
    "Data pre-processing is one of the important step of the Data Science pipeline. The quality of data and the useful information can be derived from it which directly affects our model to learn. It is also necessary to convert the categorical data to numerical as machine learning algorithm takes only numerical data. In this tutorial, you will learn basic data pre-processing steps.\n",
    "\n",
    "### Agenda\n",
    "*  Loading Libraries\n",
    "*  Loading Data\n",
    "*  Data Overview and Summary\n",
    "*  Data Pre-processing\n",
    "    *  Dropping Irrelavent Features\n",
    "    *  Dropping Rows with Missing Values\n",
    "    *  Problems with dropping rows\n",
    "    *  Taking care of missing data\n",
    "    *  Handling Categorical Variables - Creating Dummy Variables\n",
    "    * Separating input variables and output variable\n",
    "    * Splitting the data into train set and test set\n",
    "\n",
    "We are going to use the titanic dataset.\n",
    "\n",
    "## About Titanic\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "In the Hollywood blockbuster that was modelled on this tragedy, it seemed to be the case that upper-class people, women and children were more likely to survive than others. But did these properties (socio-economic status, sex and age) really influence one's survival chances?\n",
    "\n",
    "#### **Problem Identification: The goal is to predict who survived during this titanic incident (shipwreck).**\n",
    "\n",
    "#### Dataset download link\n",
    "https://docs.google.com/spreadsheets/d/1hFOPnxVT9fyT4TFlwuGGbDLfclY43P48UV24PNfAW2M/edit#gid=1297342310"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m5H5ZLLN4P7e"
   },
   "source": [
    "## Loading Libraries\n",
    "You can load all the libraries that you think will require or you can import as you go along.\n",
    "\n",
    "**Alias for libraries:** numpy --> np, pandas --> pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sz9HzzhSzm9A"
   },
   "outputs": [],
   "source": [
    "import numpy as np        # A fundamental package for linear algebra and multidimensional arrays\n",
    "import pandas as pd       # Data analysis and manipulation tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NewOrBew5xBT"
   },
   "source": [
    "## Loading Data\n",
    "The data is in csv format. Let's load the csv data using pandas read_csv() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aP7GfKaM48XX"
   },
   "outputs": [],
   "source": [
    "# I have provided the path of data which I have saved in my drive as 'titanic_train_data'.\n",
    "# You provide the path where you have saved the data.\n",
    "titanic_data = pd.read_csv(\"train - train_titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YiEmdMWh7wBY"
   },
   "source": [
    "## Data Overview and Summary\n",
    "Let's look how the data look like and a concise summary of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ZYrp9_Ju7kEC",
    "outputId": "08914861-5459-422d-ad36-932fa41533f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>598</td>\n",
       "      <td>599</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Boulos, Mr. Hanna</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2664</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>622</td>\n",
       "      <td>623</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Nakid, Mr. Sahid</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2653</td>\n",
       "      <td>15.7417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>411</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sdycoff, Mr. Todor</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349222</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Connell, Mr. Patrick D</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>334912</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ward, Miss. Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                      Name     Sex   Age  \\\n",
       "598          599         0       3         Boulos, Mr. Hanna    male   NaN   \n",
       "622          623         1       3          Nakid, Mr. Sahid    male  20.0   \n",
       "410          411         0       3        Sdycoff, Mr. Todor    male   NaN   \n",
       "629          630         0       3  O'Connell, Mr. Patrick D    male   NaN   \n",
       "258          259         1       1          Ward, Miss. Anna  female  35.0   \n",
       "\n",
       "     SibSp  Parch    Ticket      Fare Cabin Embarked  \n",
       "598      0      0      2664    7.2250   NaN        C  \n",
       "622      1      1      2653   15.7417   NaN        C  \n",
       "410      0      0    349222    7.8958   NaN        S  \n",
       "629      0      0    334912    7.7333   NaN        Q  \n",
       "258      0      0  PC 17755  512.3292   NaN        C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying 5 random records\n",
    "titanic_data.sample(5)     # You can pass the number of random records that you want to be displayed in 'sample()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJR0CeoZ8fm1"
   },
   "source": [
    "We can observe that there are some null values (i.e. NaN) in 'Age' and 'Cabin' attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "ZZAybhLZ8ZfP",
    "outputId": "cfcd8327-150d-4a26-d522-0c36bdb5c637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# A concise summary of the data\n",
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_h1fsWD863h"
   },
   "source": [
    "The concise summary of data tells us:\n",
    "*  There are total 891 observations / records in the dataset\n",
    "*  Age, Cabin and Embarked features have missing values. Cabin has a lot of missing values. Embarked has only two missing values.\n",
    "*  There are some categorical variables like Embarked, Sex, which are required to be converted into numerical.\n",
    "\n",
    "Similarly, you can observe some other information from above concise summary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LuqUvxEeV-0x"
   },
   "source": [
    "#### Exploring the attributes:\n",
    "*  'Pclass' column contains a number which indicates class of the passenger's ticket:  1 for first class, 2 for second class and 3 for third class. This could function as a proxy for the socio-economic status of the passenger ('upper', 'middle', 'low'). \n",
    "\n",
    "\n",
    "*  The 'SibSp' column contains the number of siblings + spouses of the passenger also aboard the Titanic;\n",
    "\n",
    "*  The 'ParCh' column indicates the number of parents + children of the passenger also aboard the Titanic. \n",
    "\n",
    "*  The 'Ticket' column contains the ticket numbers of passengers (which are not likely to have any predictive power regarding survival);\n",
    "\n",
    "*  'Cabin' contains the cabin number of the passenger, if he/she had a cabin, and lastly, \n",
    "\n",
    "*  'Embarked' indicates the port of embarkation of the passenger: **C**herbourg, **Q**ueenstown or **S**outhampton. The meaning of the other columns is clear, I think."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nckRIyKk9jnj"
   },
   "source": [
    "# Data Pre - processing\n",
    "Now we come to the main agenda of this tutorial i.e. data pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vmc5-Ed-bIs"
   },
   "source": [
    "### Dropping Irrelavent Features / Columns\n",
    "Here the goal is to predict the survival of the passengers. We can understand form our common sense or understanding that a person cannot survive because of his / her name, ticket number or cabin. So, we can say that these are irrelavent features. Let's drop these features from the dataset as these do not contribute much for the survival of the passenger.\n",
    "\n",
    "This is very subjective and solely depends on the nature of the dataset and underlying context. We cannot generalize this procedure to all the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9O9IBso80A2"
   },
   "outputs": [],
   "source": [
    "cols_to_drop = ['Name', 'Ticket', 'Cabin']     # columns / features to be dropped\n",
    "\n",
    "# We can use .drop() frunction of pandas to drop the columns. If you remember from the pandas session, for columns to be dropped the axis must be 1.\n",
    "titanic_data.drop(columns = cols_to_drop, axis = 1, inplace = True)     # we are making changes in the dataframe itself, so, inplace = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "52o0s9MoBRQK",
    "outputId": "24c0122a-3b65-4e21-de03-ce136961c773"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Fare', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check what columns we have using 'columns' method\n",
    "titanic_data.columns                   # returns list of columns in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL6fwyVgBg5n"
   },
   "source": [
    "If you notice, there are no 'Name', 'Ticket' and 'Cabin' features in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XV7MrMXqBs6N"
   },
   "source": [
    "### Dropping Rows with Missing Values\n",
    "We can also drop some rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gk6Lv5TEBewE"
   },
   "outputs": [],
   "source": [
    "# First let's make a copy of the dataset\n",
    "data = titanic_data.copy()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_2Sy31UgCEp9"
   },
   "source": [
    "Now, we will drop rows with missing values from 'data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UsWXV3o1CCf5"
   },
   "outputs": [],
   "source": [
    "# Again the drop() function of pandas can be used to drop rows with missing values. The only change will be axis = 0 instead of axis = 1\n",
    "data.dropna(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "ERkstxdyETgB",
    "outputId": "e3d3e9bf-2a4e-43bb-ccf5-bc86a820ff8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      "PassengerId    712 non-null int64\n",
      "Survived       712 non-null int64\n",
      "Pclass         712 non-null int64\n",
      "Sex            712 non-null object\n",
      "Age            712 non-null float64\n",
      "SibSp          712 non-null int64\n",
      "Parch          712 non-null int64\n",
      "Fare           712 non-null float64\n",
      "Embarked       712 non-null object\n",
      "dtypes: float64(2), int64(5), object(2)\n",
      "memory usage: 55.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# looking at the info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gvUbA8qeEjb1"
   },
   "source": [
    "### Problems with droping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ze4Bdn8BEXxw",
    "outputId": "5e79cd7c-00d4-49e2-bc42-104c7a9f26c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows dropped\n",
    "891- 712"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jGssO80-EgOb"
   },
   "source": [
    "If you notice here we have dropped 179 rows out of 891 rows and have lost lot of data i.e. out of 891 records, 179 records are good amount of data and we have lost those data.\n",
    "\n",
    "The more data you feed the machine learning model, the better performance it gives. So, we always try to preserve data as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "X1tufjWpEc4d",
    "outputId": "7d391a12-9028-4d1d-a26b-cb678b3c1427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(2)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# We have our titanic_data where we have not removed any rows.\n",
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_7Sip14Glrl"
   },
   "source": [
    "### Taking Care of Missing Data\n",
    "There are some missing values in 'Age' and 'Embarked' features.\n",
    "\n",
    "We can compute median or interpolate() to fill the missing values of 'Age' feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     22.0\n",
       "1     38.0\n",
       "2     26.0\n",
       "3     35.0\n",
       "4     35.0\n",
       "5      NaN\n",
       "6     54.0\n",
       "7      2.0\n",
       "8     27.0\n",
       "9     14.0\n",
       "10     4.0\n",
       "11    58.0\n",
       "12    20.0\n",
       "13    39.0\n",
       "14    14.0\n",
       "15    55.0\n",
       "16     2.0\n",
       "17     NaN\n",
       "18    31.0\n",
       "19     NaN\n",
       "20    35.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data['Age'].head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMTMhQIOGczp"
   },
   "outputs": [],
   "source": [
    "titanic_data['Age'] = titanic_data['Age'].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     22.0\n",
       "1     38.0\n",
       "2     26.0\n",
       "3     35.0\n",
       "4     35.0\n",
       "5     44.5\n",
       "6     54.0\n",
       "7      2.0\n",
       "8     27.0\n",
       "9     14.0\n",
       "10     4.0\n",
       "11    58.0\n",
       "12    20.0\n",
       "13    39.0\n",
       "14    14.0\n",
       "15    55.0\n",
       "16     2.0\n",
       "17    16.5\n",
       "18    31.0\n",
       "19    33.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data['Age'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xj_MSQ-3LAaZ"
   },
   "source": [
    "'Embarked' is a categorical variable. Let's take a look at its unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qdC6mMn9IkiW",
    "outputId": "884827a1-df11-4c7f-a6e2-51ae1d7f25a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.Embarked.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeQzAmdmLNZt"
   },
   "source": [
    "There are 3 unique values with two missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "2kGGvbhXLKQJ",
    "outputId": "d6efeca3-c53c-412b-aca5-fb8e8ce97ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at frequency of each values in 'Embarked'\n",
    "titanic_data.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "netEJSzjLhft"
   },
   "source": [
    "'S' is the most occuring value in 'Embarked' column. So, we can fill the two missing values with 'S' assuming that the two passengers whose port of Embarkation is missing might have embarked from 'Southampton' i.e. 'S'.\n",
    "\n",
    "Let's fill the null values of Embarked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dEqseBNELgAs"
   },
   "outputs": [],
   "source": [
    "# We can use fillna() function to fill the missing values as discussed in the pandas session / notebook.\n",
    "titanic_data.Embarked.fillna(value='S', axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "rXRpe8fQMyND",
    "outputId": "ea24d7c2-560c-4092-ae4e-df9c52b4872b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "Embarked       891 non-null object\n",
      "dtypes: float64(2), int64(5), object(2)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# We can check if there still exist any missing value using the info() method\n",
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F4S0syE1NHsF"
   },
   "source": [
    "All the features have 891 non - null values. Now we don't have nay missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_Q7PjzCNaJr"
   },
   "source": [
    "### Handling Categorical Variables - Creating Dummy Variables\n",
    "There are many methods of dealing with categorical data. One of the known method is creating dummy variables.\n",
    "\n",
    "**Creating Dummy Variables:**\n",
    "Let's understand using Embarked feature. This feature has 3 unique values. \n",
    "In this case 3 new features will be created - 'C', 'Q' and 'S'. If the passenger had embarked from 'Cherbourg' (i.e. C), the newly generated column 'C' will have its value as 1 else 0 and similarly for other dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtmJrGQ3TdgH"
   },
   "source": [
    "There are three categorical feature with us in this dataset - Pclaa, Sex and Embarked. Let's create dummy variables for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rBIVoxfaNFUp"
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.get_dummies(titanic_data, columns=['Pclass', 'Sex', 'Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "UsIyl7dGUtrn",
    "outputId": "c8b7e18a-487c-46c4-88dc-0cd69639281a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived   Age  SibSp  Parch  Fare  Pclass_1  Pclass_2  \\\n",
       "0            1         0  22.0      1      0  7.25         0         0   \n",
       "\n",
       "   Pclass_3  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1           0         1           0           0           1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HFpjLSJHVRgp"
   },
   "source": [
    "The columns: Pclass_1, Pclass_2, Pclass_3, Sex_female, Sex_male, Embarked_C, Embarked_Q and Embarked_S are our dummy variables. The original columns are dropped by itself from the dataframe. If we had created dummhy variables separately for each column and then concatenated all those variables to the datafram then we had needed to drop those parent columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaeUqGDsXObz"
   },
   "source": [
    "### Separating Target and Input Features\n",
    "We feed the data to the algorithms as the input features (i.e. independent variables) and the target feature (i.e. dependent variable). So, we separate these features form the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mz6DgGyPUvRg"
   },
   "outputs": [],
   "source": [
    "X = titanic_data.drop(columns=['Survived'])     # these are independent features. The change of dropping the column 'Survived' is not inplace.\n",
    "\n",
    "Y = titanic_data.Survived               # The target feature or dependent feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "trmrdc7XYY8K"
   },
   "source": [
    "### Splitting data into Train set and Test set\n",
    "The test set of the data is used to check how the built model is performing.\n",
    "Generally, people use 70% of the data for trainig the model and 30% for testing the model. Some people also use the ratio as 80% or 90% for training and 20% or 10%  for testing.\n",
    "\n",
    "The splitting is done using train_test_split class from sklearn.model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYXiNVTwYSzu"
   },
   "outputs": [],
   "source": [
    "# import the class\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# X_train: independent feature data for training the model\n",
    "# Y_train: dependent feature data for training the model\n",
    "# X_test: independent feature data for testing the model; will be used to predict the target values\n",
    "# Y_test: original target values of X_test; We will compare this values with our predicted values.\n",
    " \n",
    "# test_size = 0.30: 30% of the data will go for test set and 70% of the data will go for train set\n",
    "# random_state = 42: this will fix the split i.e. there will be same split for each time you run the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yhlPghgXalRk"
   },
   "source": [
    "# Conclusion\n",
    "That's it in this tutorial about Data Pre - processing. Here we discussed some basic stuff about data pre - processing. Later we will learn stuffs like standardization, normalization, One Hot Encoding, etc. in data pre - processing.\n",
    "Thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zxa4WdfybUzi"
   },
   "source": [
    "#### **References:**\n",
    "1. [Implementation of Data Preprocessing on Titanic Dataset by Afroz Chakure](https://towardsdatascience.com/implementation-of-data-preprocessing-on-titanic-dataset-6c553bef0bc6)\n",
    "2. [Data Pre-Processing By Ayon Roy at DPhi](https://www.youtube.com/watch?v=ni5BO0mO1x8)\n",
    "3. [Introduction to Data Preprocessing in Machine Learning by Dhairya Kumar](https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d#:~:text=Data%20preprocessing%20is%20an%20integral,feeding%20it%20into%20our%20model.)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data Pre-processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
